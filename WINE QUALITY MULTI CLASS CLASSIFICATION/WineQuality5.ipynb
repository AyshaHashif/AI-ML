{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOi4VdCnIZ78yUe8e4ewexM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GNxh1cwyufr9","executionInfo":{"status":"ok","timestamp":1741755721732,"user_tz":-330,"elapsed":923,"user":{"displayName":"Aysha Hashif","userId":"03722952912424320427"}},"outputId":"ad55c894-1563-40b1-ed06-eb5a0632f19d"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Logistic Regression Evaluation ---\n","              precision    recall  f1-score   support\n","\n","           4       1.00      0.00      0.00         3\n","           5       0.62      0.77      0.69        62\n","           6       0.65      0.63      0.64        81\n","           7       0.67      0.42      0.51        24\n","           8       1.00      0.00      0.00         1\n","\n","    accuracy                           0.64       171\n","   macro avg       0.79      0.36      0.37       171\n","weighted avg       0.65      0.64      0.62       171\n","\n","Confusion Matrix:\n","[[ 0  2  1  0  0]\n"," [ 0 48 13  1  0]\n"," [ 0 26 51  4  0]\n"," [ 0  2 12 10  0]\n"," [ 0  0  1  0  0]]\n","Accuracy: 0.6374269005847953\n","--- Decision Tree Evaluation ---\n","              precision    recall  f1-score   support\n","\n","           3       0.00      1.00      0.00         0\n","           4       0.00      0.00      0.00         3\n","           5       0.67      0.71      0.69        62\n","           6       0.67      0.60      0.64        81\n","           7       0.54      0.54      0.54        24\n","           8       0.17      1.00      0.29         1\n","\n","    accuracy                           0.63       171\n","   macro avg       0.34      0.64      0.36       171\n","weighted avg       0.64      0.63      0.63       171\n","\n","Confusion Matrix:\n","[[ 0  0  0  0  0  0]\n"," [ 0  0  2  1  0  0]\n"," [ 0  1 44 14  3  0]\n"," [ 1  0 20 49  8  3]\n"," [ 0  0  0  9 13  2]\n"," [ 0  0  0  0  0  1]]\n","Accuracy: 0.6257309941520468\n","--- K-Nearest Neighbors Evaluation ---\n","              precision    recall  f1-score   support\n","\n","           4       0.00      0.00      0.00         3\n","           5       0.55      0.71      0.62        62\n","           6       0.61      0.54      0.58        81\n","           7       0.59      0.42      0.49        24\n","           8       1.00      0.00      0.00         1\n","\n","    accuracy                           0.57       171\n","   macro avg       0.55      0.33      0.34       171\n","weighted avg       0.58      0.57      0.57       171\n","\n","Confusion Matrix:\n","[[ 0  2  1  0  0]\n"," [ 1 44 17  0  0]\n"," [ 1 29 44  7  0]\n"," [ 0  4 10 10  0]\n"," [ 0  1  0  0  0]]\n","Accuracy: 0.5730994152046783\n"]}],"source":["# 5. Evaluation Metrics\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.datasets import load_wine # import wine quality Dataset\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from imblearn.over_sampling import SMOTE\n","\n","\n","data_ar = pd.read_csv('/content/WineQT.csv')\n","\n","\n","\n","# Feature Scaling\n","scaler = StandardScaler()\n","X = data_ar.drop('quality', axis=1)\n","y = data_ar['quality']\n","X_scaled = scaler.fit_transform(X)\n","\n","# Splitting Data\n","X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","\n","#Logistic Regression\n","logreg = LogisticRegression(max_iter=5000)\n","logreg.fit(X_train, y_train)\n","y_val_pred_logreg = logreg.predict(X_val)\n","\n","# Decision Tree\n","dt = DecisionTreeClassifier(random_state=42)\n","dt.fit(X_train, y_train)\n","y_val_pred_dt = dt.predict(X_val)\n","\n","# K-Nearest Neighbors\n","knn = KNeighborsClassifier()\n","knn.fit(X_train, y_train)\n","y_val_pred_knn = knn.predict(X_val)\n","\n","\n","def evaluate_model(y_true, y_pred, model_name):\n","    print(f\"--- {model_name} Evaluation ---\")\n","    print(classification_report(y_true, y_pred,zero_division=1))\n","    print(\"Confusion Matrix:\")\n","    print(confusion_matrix(y_true, y_pred))\n","    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n","\n","evaluate_model(y_val, y_val_pred_logreg, \"Logistic Regression\")\n","evaluate_model(y_val, y_val_pred_dt, \"Decision Tree\")\n","evaluate_model(y_val, y_val_pred_knn, \"K-Nearest Neighbors\")"]}]}