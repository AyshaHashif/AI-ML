{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOlb3O96NmV/jFOK2P9MG2a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XybVSB3Bv3aZ","executionInfo":{"status":"ok","timestamp":1741756102302,"user_tz":-330,"elapsed":5176,"user":{"displayName":"Aysha Hashif","userId":"03722952912424320427"}},"outputId":"2839402d-a2b9-4771-963e-422a7af924fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Tuned Logistic Regression Evaluation ---\n","              precision    recall  f1-score   support\n","\n","           4       1.00      0.00      0.00         3\n","           5       0.62      0.77      0.69        62\n","           6       0.65      0.63      0.64        81\n","           7       0.67      0.42      0.51        24\n","           8       1.00      0.00      0.00         1\n","\n","    accuracy                           0.64       171\n","   macro avg       0.79      0.36      0.37       171\n","weighted avg       0.65      0.64      0.62       171\n","\n","Confusion Matrix:\n","[[ 0  2  1  0  0]\n"," [ 0 48 13  1  0]\n"," [ 0 26 51  4  0]\n"," [ 0  2 12 10  0]\n"," [ 0  0  1  0  0]]\n","Accuracy: 0.6374269005847953\n","--- Tuned Decision Tree Evaluation ---\n","              precision    recall  f1-score   support\n","\n","           3       0.00      1.00      0.00         0\n","           4       0.00      0.00      0.00         3\n","           5       0.69      0.74      0.71        62\n","           6       0.61      0.67      0.64        81\n","           7       0.45      0.21      0.29        24\n","           8       0.00      0.00      0.00         1\n","\n","    accuracy                           0.61       171\n","   macro avg       0.29      0.44      0.27       171\n","weighted avg       0.60      0.61      0.60       171\n","\n","Confusion Matrix:\n","[[ 0  0  0  0  0  0]\n"," [ 0  0  2  1  0  0]\n"," [ 0  1 46 15  0  0]\n"," [ 1  1 18 54  6  1]\n"," [ 0  1  1 17  5  0]\n"," [ 0  0  0  1  0  0]]\n","Accuracy: 0.6140350877192983\n","--- Tuned K-Nearest Neighbors Evaluation ---\n","              precision    recall  f1-score   support\n","\n","           4       1.00      0.00      0.00         3\n","           5       0.60      0.77      0.68        62\n","           6       0.67      0.59      0.63        81\n","           7       0.68      0.54      0.60        24\n","           8       1.00      0.00      0.00         1\n","\n","    accuracy                           0.64       171\n","   macro avg       0.79      0.38      0.38       171\n","weighted avg       0.65      0.64      0.63       171\n","\n","Confusion Matrix:\n","[[ 0  2  1  0  0]\n"," [ 0 48 12  2  0]\n"," [ 0 29 48  4  0]\n"," [ 0  1 10 13  0]\n"," [ 0  0  1  0  0]]\n","Accuracy: 0.6374269005847953\n"]}],"source":["# 6.Hyperparameter Tuning\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.datasets import load_wine # import wine quality Dataset\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from imblearn.over_sampling import SMOTE\n","\n","\n","data_ar = pd.read_csv('/content/WineQT.csv')\n","\n"," # Feature Scaling\n","scaler = StandardScaler()\n","X = data_ar.drop('quality', axis=1)\n","y = data_ar['quality']\n","X_scaled = scaler.fit_transform(X)\n","\n","\n","# Splitting Data\n","X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","\n","\n","def evaluate_model(y_true, y_pred, model_name):\n","    print(f\"--- {model_name} Evaluation ---\")\n","    print(classification_report(y_true, y_pred,zero_division=1))\n","    print(\"Confusion Matrix:\")\n","    print(confusion_matrix(y_true, y_pred))\n","    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n","\n","\n","\n","# 6. Hyperparameter Tuning using Grid Search\n","\n","# Logistic Regression Tuning\n","param_grid_logreg = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n","grid_search_logreg = GridSearchCV(LogisticRegression(max_iter=5000), param_grid_logreg, cv=5)\n","grid_search_logreg.fit(X_train, y_train)\n","best_logreg = grid_search_logreg.best_estimator_\n","y_val_pred_best_logreg = best_logreg.predict(X_val)\n","\n","# Decision Tree Tuning\n","param_grid_dt = {'max_depth': [3, 5, 7, 10, None], 'min_samples_split': [2, 5, 10]}\n","grid_search_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=5)\n","grid_search_dt.fit(X_train, y_train)\n","best_dt = grid_search_dt.best_estimator_\n","y_val_pred_best_dt = best_dt.predict(X_val)\n","\n","# KNN Tuning\n","param_grid_knn = {'n_neighbors': [3, 5, 7, 10]}\n","grid_search_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5)\n","grid_search_knn.fit(X_train, y_train)\n","best_knn = grid_search_knn.best_estimator_\n","y_val_pred_best_knn = best_knn.predict(X_val)\n","\n","evaluate_model(y_val, y_val_pred_best_logreg, \"Tuned Logistic Regression\")\n","evaluate_model(y_val, y_val_pred_best_dt, \"Tuned Decision Tree\")\n","evaluate_model(y_val, y_val_pred_best_knn, \"Tuned K-Nearest Neighbors\")"]}]}