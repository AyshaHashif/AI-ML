{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOFVMrVr3Hpdae3Rc+tz7hv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SpeFSESFwaAD","executionInfo":{"status":"ok","timestamp":1741757185734,"user_tz":-330,"elapsed":2391,"user":{"displayName":"Aysha Hashif","userId":"03722952912424320427"}},"outputId":"b51e0b0e-7e58-4e83-cc35-cba6b4a89d7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n","0            7.4              0.70         0.00             1.9      0.076   \n","1            7.8              0.88         0.00             2.6      0.098   \n","2            7.8              0.76         0.04             2.3      0.092   \n","3           11.2              0.28         0.56             1.9      0.075   \n","4            7.4              0.70         0.00             1.9      0.076   \n","\n","   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n","0                 11.0                  34.0   0.9978  3.51       0.56   \n","1                 25.0                  67.0   0.9968  3.20       0.68   \n","2                 15.0                  54.0   0.9970  3.26       0.65   \n","3                 17.0                  60.0   0.9980  3.16       0.58   \n","4                 11.0                  34.0   0.9978  3.51       0.56   \n","\n","   alcohol  quality  Id  \n","0      9.4        5   0  \n","1      9.8        5   1  \n","2      9.8        5   2  \n","3      9.8        6   3  \n","4      9.4        5   4  \n","Missing Values Before Handling:\n","fixed acidity           0\n","volatile acidity        0\n","citric acid             0\n","residual sugar          0\n","chlorides               0\n","free sulfur dioxide     0\n","total sulfur dioxide    0\n","density                 0\n","pH                      0\n","sulphates               0\n","alcohol                 0\n","quality                 0\n","Id                      0\n","dtype: int64\n","quality\n","5    483\n","6    483\n","7    483\n","4    483\n","8    483\n","3    483\n","Name: count, dtype: int64\n","Final Test Evaluation for Logistic Regression:\n","==Logistic Regression Performance ==\n","              precision    recall  f1-score   support\n","\n","           3       0.87      1.00      0.93        72\n","           4       0.59      0.61      0.60        72\n","           5       0.60      0.56      0.58        73\n","           6       0.56      0.44      0.49        73\n","           7       0.63      0.51      0.56        73\n","           8       0.69      0.89      0.78        72\n","\n","    accuracy                           0.67       435\n","   macro avg       0.66      0.67      0.66       435\n","weighted avg       0.66      0.67      0.66       435\n","\n","The Confusion Matrix is :\n","[[72  0  0  0  0  0]\n"," [ 2 44 15  7  3  1]\n"," [ 7 14 41  4  4  3]\n"," [ 2 14 11 32  7  7]\n"," [ 0  3  1 14 37 18]\n"," [ 0  0  0  0  8 64]]\n","precision: 0.6556286530843011\n","Final Test Evaluation for Decision Tree:\n","==Decision Tree Performance ==\n","              precision    recall  f1-score   support\n","\n","           3       0.99      1.00      0.99        72\n","           4       0.80      0.85      0.82        72\n","           5       0.61      0.56      0.59        73\n","           6       0.47      0.47      0.47        73\n","           7       0.76      0.68      0.72        73\n","           8       0.84      0.93      0.88        72\n","\n","    accuracy                           0.75       435\n","   macro avg       0.74      0.75      0.74       435\n","weighted avg       0.74      0.75      0.74       435\n","\n","The Confusion Matrix is :\n","[[72  0  0  0  0  0]\n"," [ 0 61  7  3  1  0]\n"," [ 1  5 41 18  5  3]\n"," [ 0  8 18 34  9  4]\n"," [ 0  2  1 14 50  6]\n"," [ 0  0  0  4  1 67]]\n","precision: 0.7436170715918563\n","Final Test Evaluation for K-Nearest Neighbors:\n","==K-Nearest Neighbors Performance ==\n","              precision    recall  f1-score   support\n","\n","           3       0.62      0.86      0.72        72\n","           4       0.63      0.88      0.73        72\n","           5       0.50      0.44      0.47        73\n","           6       0.48      0.30      0.37        73\n","           7       0.62      0.68      0.65        73\n","           8       0.87      0.54      0.67        72\n","\n","    accuracy                           0.62       435\n","   macro avg       0.62      0.62      0.60       435\n","weighted avg       0.62      0.62      0.60       435\n","\n","The Confusion Matrix is :\n","[[62  2  3  2  2  1]\n"," [ 6 63  2  1  0  0]\n"," [10 13 32 10  6  2]\n"," [14 11 16 22  9  1]\n"," [ 1  8  6  6 50  2]\n"," [ 7  3  5  5 13 39]]\n","precision: 0.619987922705314\n"]}],"source":["# 7. Final Model Testing and Evaluation\n","import pandas as pd\n","from sklearn.datasets import load_wine\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n","from imblearn.over_sampling import SMOTE\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import GridSearchCV\n","\n","data = pd.read_csv('/content/WineQT.csv')\n","\n","# Data Inspection\n","print(data.head())\n","\n","# 3. Data Preparation\n","# 2. Check for Missing Values\n","print(\"Missing Values Before Handling:\")\n","print(data.isnull().sum())\n","\n","# Remove duplicates\n","df = data.drop_duplicates()\n","\n","# Handle Class Imbalance using SMOTE\n","X = data.drop(columns=[\"quality\"])  # Features\n","y = data[\"quality\"]  # Target variable\n","\n","# Apply SMOTE to balance classes\n","smote = SMOTE(random_state=42)\n","X_resampled, y_resampled = smote.fit_resample(X, y)\n","\n","# Check the new class distribution\n","print(y_resampled.value_counts())\n","\n","# Feature Scaling\n","scaler = StandardScaler()\n","\n","# Split data into training, validation, and test sets\n","X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n","\n","# Scale the features\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_val_scaled = scaler.transform(X_val)\n","X_test_scaled = scaler.transform(X_test)\n","\n","\n","\n","def evaluate_model(y_true, y_pred, model_name):\n","    print(f\"=={model_name} Performance ==\")\n","    print(classification_report(y_true, y_pred, zero_division=1))\n","    print(\"The Confusion Matrix is :\")\n","    print(confusion_matrix(y_true, y_pred))\n","    print(\"precision:\", precision_score(y_true, y_pred, average='macro', zero_division=1))\n","\n","\n","# Logistic Regression Tuning\n","param_grid_logreg = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n","grid_search_logreg = GridSearchCV(LogisticRegression(max_iter=10000, solver='lbfgs'), param_grid_logreg, cv=3)\n","grid_search_logreg.fit(X_train_scaled, y_train)\n","best_logreg = grid_search_logreg.best_estimator_\n","\n","# Predictions using best Logistic Regression model\n","y_val_pred_best_logreg = best_logreg.predict(X_val_scaled)\n","\n","\n","# Decision Tree Classifier Tuning\n","param_grid_dt = {'max_depth': [2, 4, 6, 9, None], 'min_samples_split': [3, 6, 11]}\n","grid_search_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3)\n","grid_search_dt.fit(X_train, y_train)\n","best_dt = grid_search_dt.best_estimator_\n","\n","# Predictions using best Decision Tree model\n","y_val_pred_best_dt = best_dt.predict(X_val)\n","\n","\n","# K-Nearest Neighbors Tuning\n","param_knn = {'n_neighbors': [2, 4, 6, 9]}\n","grid_search_knn = GridSearchCV(KNeighborsClassifier(), param_knn, cv=3)\n","grid_search_knn.fit(X_train, y_train)\n","best_knn = grid_search_knn.best_estimator_\n","\n","# Predictions using best KNN model\n","y_val_pred_best_knn = best_knn.predict(X_val)\n","\n","\n","\n","\n","# 7. Final Model Testing and Evaluation\n","\n","# Logistic Regression Test Evaluation\n","y_test_pred_log = best_logreg.predict(X_test_scaled)\n","print(\"Final Test Evaluation for Logistic Regression:\")\n","evaluate_model(y_test, y_test_pred_log, \"Logistic Regression\")\n","\n","# Decision Tree Test Evaluation\n","y_test_pred_tree = best_dt.predict(X_test)\n","print(\"Final Test Evaluation for Decision Tree:\")\n","evaluate_model(y_test, y_test_pred_tree, \"Decision Tree\")\n","\n","# KNN Test Evaluation\n","y_test_pred_knn = best_knn.predict(X_test)\n","print(\"Final Test Evaluation for K-Nearest Neighbors:\")\n","evaluate_model(y_test, y_test_pred_knn, \"K-Nearest Neighbors\")\n","\n"]}]}